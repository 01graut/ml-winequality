{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import MinMaxScaler, StandardScaler\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import IntegerType, DoubleType\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"TrainTestWorkflow\").getOrCreate()\n",
    "\n",
    "# Load the datasets\n",
    "train_data_path = \"/workspaces/ml-winequality/dataset/TrainingDataset.csv\"\n",
    "test_data_path = \"/workspaces/ml-winequality/dataset/ValidationDataset.csv\"\n",
    "\n",
    "train_df = spark.read.csv(train_data_path,header=True, \n",
    "                      inferSchema=True,\n",
    "                      sep=';'\n",
    "                      ,quote='\"')\n",
    "test_df = spark.read.csv(test_data_path,header=True, \n",
    "                      inferSchema=True,\n",
    "                      sep=';'\n",
    "                      ,quote='\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used copilot how to get rid of quotes from colum header\n",
    "new_column_names = [col_name.strip('\"') for col_name in train_df.columns]\n",
    "train_df = train_df.toDF(*new_column_names)\n",
    "\n",
    "# Used copilot how to get rid of quotes from colum header\n",
    "new_column_names = [col_name.strip('\"') for col_name in test_df.columns]\n",
    "test_df = test_df.toDF(*new_column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imbalance data set, Resize using SMOTE\n",
    "# import SMOTE\n",
    "# sm = SMOTE(random_state=14)\n",
    "# # X_train, Y_train = sm.fit_resample(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "\n",
    "# Assemble features\n",
    "featureCols = train_df.columns[:-1]  # Assuming the last column is the label\n",
    "assembler = VectorAssembler(inputCols=featureCols, outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Initialize the model\n",
    "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"quality\")\n",
    "\n",
    "# Create a Pipeline\n",
    "pipeline = Pipeline(stages=[assembler, rf])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "fitted_pipeline = pipeline.fit(train_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model F1 Score on Test Data: 0.4865269070010449\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql.functions import *\n",
    "# Make predictions on test data\n",
    "# Make predictions\n",
    "predictions = fitted_pipeline.transform(test_df)\n",
    "\n",
    "predictions = predictions.withColumn(\"prediction\", round(col(\"prediction\"),0).cast(\"double\"))\n",
    "# Evaluate the best model\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"quality\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "f1_score = evaluator.evaluate(predictions)\n",
    "\n",
    "print(f\"Best Model F1 Score on Test Data: {f1_score}\")\n",
    "# Best Model F1 Score on Test Data: 0.4865269070010449\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "############################# Part 2\n",
    "Using MinMaxScalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/30 18:06:09 WARN DAGScheduler: Broadcasting large task binary with size 1133.9 KiB\n",
      "24/03/30 18:06:09 WARN DAGScheduler: Broadcasting large task binary with size 1347.6 KiB\n",
      "24/03/30 18:06:09 WARN DAGScheduler: Broadcasting large task binary with size 1528.8 KiB\n",
      "24/03/30 18:06:10 WARN DAGScheduler: Broadcasting large task binary with size 1670.7 KiB\n",
      "24/03/30 18:06:10 WARN DAGScheduler: Broadcasting large task binary with size 1777.1 KiB\n",
      "24/03/30 18:06:10 WARN DAGScheduler: Broadcasting large task binary with size 1851.3 KiB\n",
      "24/03/30 18:06:10 WARN DAGScheduler: Broadcasting large task binary with size 1753.6 KiB\n",
      "24/03/30 18:06:10 WARN DAGScheduler: Broadcasting large task binary with size 1404.9 KiB\n",
      "24/03/30 18:06:10 WARN DAGScheduler: Broadcasting large task binary with size 1194.3 KiB\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Assemble features\n",
    "featureCols = train_df.columns[:-1]  # Assuming the last column is the label\n",
    "\n",
    "# MINMAXSCALAR\n",
    "\n",
    "# Assemble features\n",
    "assembler = VectorAssembler(inputCols=featureCols, outputCol=\"assembledFeatures\")\n",
    "\n",
    "# Normalize features using Min-Max Scaling\n",
    "scaler = MinMaxScaler(inputCol=\"assembledFeatures\", outputCol=\"normalizedFeatures\")\n",
    "\n",
    "# Initialize the model\n",
    "model = RandomForestRegressor(featuresCol=\"normalizedFeatures\", labelCol='quality',\n",
    "                              maxDepth=20,\n",
    "                              numTrees=25,\n",
    "                              seed=42,\n",
    "                              )\n",
    "\n",
    "\n",
    "# Create a Pipeline\n",
    "pipeline2 = Pipeline(stages=[assembler, scaler, model])\n",
    "\n",
    "# Train the model\n",
    "fitted_pipeline2 = pipeline2.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model F1 Score on Test Data: 0.6122891944715902\n"
     ]
    }
   ],
   "source": [
    "# Evaluate using MixMax Scalar\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql.functions import *\n",
    "# Make predictions on test data\n",
    "# Make predictions\n",
    "predictions = fitted_pipeline2.transform(test_df)\n",
    "\n",
    "predictions = predictions.withColumn(\"prediction\", round(col(\"prediction\"),0).cast(\"double\"))\n",
    "# Evaluate the best model\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"quality\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "f1_score = evaluator.evaluate(predictions)\n",
    "\n",
    "print(f\"Best Model F1 Score on Test Data: {f1_score}\")\n",
    "# Best Model F1 Score on Test Data: 0.6034063260340633"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part3 Using Cross Validator + MinMax Scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/30 17:45:00 WARN DAGScheduler: Broadcasting large task binary with size 1076.3 KiB\n",
      "24/03/30 17:45:00 WARN DAGScheduler: Broadcasting large task binary with size 1205.9 KiB\n",
      "24/03/30 17:45:00 WARN DAGScheduler: Broadcasting large task binary with size 1302.2 KiB\n",
      "24/03/30 17:45:00 WARN DAGScheduler: Broadcasting large task binary with size 1370.4 KiB\n",
      "24/03/30 17:45:00 WARN DAGScheduler: Broadcasting large task binary with size 1419.2 KiB\n",
      "24/03/30 17:45:02 WARN DAGScheduler: Broadcasting large task binary with size 1045.8 KiB\n",
      "24/03/30 17:45:02 WARN DAGScheduler: Broadcasting large task binary with size 1294.7 KiB\n",
      "24/03/30 17:45:03 WARN DAGScheduler: Broadcasting large task binary with size 1045.8 KiB\n",
      "24/03/30 17:45:03 WARN DAGScheduler: Broadcasting large task binary with size 1294.7 KiB\n",
      "24/03/30 17:45:03 WARN DAGScheduler: Broadcasting large task binary with size 1524.4 KiB\n",
      "24/03/30 17:45:03 WARN DAGScheduler: Broadcasting large task binary with size 1724.7 KiB\n",
      "24/03/30 17:45:04 WARN DAGScheduler: Broadcasting large task binary with size 1884.5 KiB\n",
      "24/03/30 17:45:04 WARN DAGScheduler: Broadcasting large task binary with size 2004.5 KiB\n",
      "24/03/30 17:45:04 WARN DAGScheduler: Broadcasting large task binary with size 2016.1 KiB\n",
      "24/03/30 17:45:10 WARN DAGScheduler: Broadcasting large task binary with size 1099.2 KiB\n",
      "24/03/30 17:45:10 WARN DAGScheduler: Broadcasting large task binary with size 1231.9 KiB\n",
      "24/03/30 17:45:10 WARN DAGScheduler: Broadcasting large task binary with size 1330.7 KiB\n",
      "24/03/30 17:45:10 WARN DAGScheduler: Broadcasting large task binary with size 1401.9 KiB\n",
      "24/03/30 17:45:10 WARN DAGScheduler: Broadcasting large task binary with size 1452.7 KiB\n",
      "24/03/30 17:45:12 WARN DAGScheduler: Broadcasting large task binary with size 1074.7 KiB\n",
      "24/03/30 17:45:12 WARN DAGScheduler: Broadcasting large task binary with size 1336.6 KiB\n",
      "24/03/30 17:45:13 WARN DAGScheduler: Broadcasting large task binary with size 1074.7 KiB\n",
      "24/03/30 17:45:13 WARN DAGScheduler: Broadcasting large task binary with size 1336.6 KiB\n",
      "24/03/30 17:45:13 WARN DAGScheduler: Broadcasting large task binary with size 1571.8 KiB\n",
      "24/03/30 17:45:14 WARN DAGScheduler: Broadcasting large task binary with size 1766.8 KiB\n",
      "24/03/30 17:45:14 WARN DAGScheduler: Broadcasting large task binary with size 1913.5 KiB\n",
      "24/03/30 17:45:14 WARN DAGScheduler: Broadcasting large task binary with size 2023.1 KiB\n",
      "24/03/30 17:45:14 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "24/03/30 17:45:19 WARN DAGScheduler: Broadcasting large task binary with size 1068.9 KiB\n",
      "24/03/30 17:45:20 WARN DAGScheduler: Broadcasting large task binary with size 1202.9 KiB\n",
      "24/03/30 17:45:20 WARN DAGScheduler: Broadcasting large task binary with size 1304.8 KiB\n",
      "24/03/30 17:45:20 WARN DAGScheduler: Broadcasting large task binary with size 1379.4 KiB\n",
      "24/03/30 17:45:20 WARN DAGScheduler: Broadcasting large task binary with size 1433.5 KiB\n",
      "24/03/30 17:45:22 WARN DAGScheduler: Broadcasting large task binary with size 1093.5 KiB\n",
      "24/03/30 17:45:22 WARN DAGScheduler: Broadcasting large task binary with size 1361.4 KiB\n",
      "24/03/30 17:45:23 WARN DAGScheduler: Broadcasting large task binary with size 1093.5 KiB\n",
      "24/03/30 17:45:23 WARN DAGScheduler: Broadcasting large task binary with size 1361.4 KiB\n",
      "24/03/30 17:45:23 WARN DAGScheduler: Broadcasting large task binary with size 1602.1 KiB\n",
      "24/03/30 17:45:24 WARN DAGScheduler: Broadcasting large task binary with size 1805.0 KiB\n",
      "24/03/30 17:45:24 WARN DAGScheduler: Broadcasting large task binary with size 1958.3 KiB\n",
      "24/03/30 17:45:24 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "24/03/30 17:45:24 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "24/03/30 17:45:30 WARN DAGScheduler: Broadcasting large task binary with size 1117.1 KiB\n",
      "24/03/30 17:45:30 WARN DAGScheduler: Broadcasting large task binary with size 1254.0 KiB\n",
      "24/03/30 17:45:30 WARN DAGScheduler: Broadcasting large task binary with size 1354.2 KiB\n",
      "24/03/30 17:45:30 WARN DAGScheduler: Broadcasting large task binary with size 1423.6 KiB\n",
      "24/03/30 17:45:30 WARN DAGScheduler: Broadcasting large task binary with size 1472.9 KiB\n",
      "24/03/30 17:45:33 WARN DAGScheduler: Broadcasting large task binary with size 1082.6 KiB\n",
      "24/03/30 17:45:33 WARN DAGScheduler: Broadcasting large task binary with size 1354.8 KiB\n",
      "24/03/30 17:45:34 WARN DAGScheduler: Broadcasting large task binary with size 1082.6 KiB\n",
      "24/03/30 17:45:35 WARN DAGScheduler: Broadcasting large task binary with size 1354.8 KiB\n",
      "24/03/30 17:45:35 WARN DAGScheduler: Broadcasting large task binary with size 1602.3 KiB\n",
      "24/03/30 17:45:35 WARN DAGScheduler: Broadcasting large task binary with size 1808.0 KiB\n",
      "24/03/30 17:45:35 WARN DAGScheduler: Broadcasting large task binary with size 1957.7 KiB\n",
      "24/03/30 17:45:35 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "24/03/30 17:45:35 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "24/03/30 17:45:41 WARN DAGScheduler: Broadcasting large task binary with size 1059.3 KiB\n",
      "24/03/30 17:45:41 WARN DAGScheduler: Broadcasting large task binary with size 1195.1 KiB\n",
      "24/03/30 17:45:41 WARN DAGScheduler: Broadcasting large task binary with size 1300.2 KiB\n",
      "24/03/30 17:45:41 WARN DAGScheduler: Broadcasting large task binary with size 1374.2 KiB\n",
      "24/03/30 17:45:41 WARN DAGScheduler: Broadcasting large task binary with size 1427.7 KiB\n",
      "24/03/30 17:45:43 WARN DAGScheduler: Broadcasting large task binary with size 1072.4 KiB\n",
      "24/03/30 17:45:43 WARN DAGScheduler: Broadcasting large task binary with size 1342.2 KiB\n",
      "24/03/30 17:45:44 WARN DAGScheduler: Broadcasting large task binary with size 1072.3 KiB\n",
      "24/03/30 17:45:44 WARN DAGScheduler: Broadcasting large task binary with size 1342.2 KiB\n",
      "24/03/30 17:45:45 WARN DAGScheduler: Broadcasting large task binary with size 1576.7 KiB\n",
      "24/03/30 17:45:45 WARN DAGScheduler: Broadcasting large task binary with size 1773.6 KiB\n",
      "24/03/30 17:45:45 WARN DAGScheduler: Broadcasting large task binary with size 1926.5 KiB\n",
      "24/03/30 17:45:45 WARN DAGScheduler: Broadcasting large task binary with size 2037.6 KiB\n",
      "24/03/30 17:45:45 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "24/03/30 17:45:51 WARN DAGScheduler: Broadcasting large task binary with size 1066.1 KiB\n",
      "24/03/30 17:45:51 WARN DAGScheduler: Broadcasting large task binary with size 1193.1 KiB\n",
      "24/03/30 17:45:51 WARN DAGScheduler: Broadcasting large task binary with size 1297.0 KiB\n",
      "24/03/30 17:45:51 WARN DAGScheduler: Broadcasting large task binary with size 1376.2 KiB\n",
      "24/03/30 17:45:51 WARN DAGScheduler: Broadcasting large task binary with size 1430.3 KiB\n",
      "24/03/30 17:45:53 WARN DAGScheduler: Broadcasting large task binary with size 1082.2 KiB\n",
      "24/03/30 17:45:54 WARN DAGScheduler: Broadcasting large task binary with size 1354.7 KiB\n",
      "24/03/30 17:45:55 WARN DAGScheduler: Broadcasting large task binary with size 1082.2 KiB\n",
      "24/03/30 17:45:55 WARN DAGScheduler: Broadcasting large task binary with size 1354.7 KiB\n",
      "24/03/30 17:45:55 WARN DAGScheduler: Broadcasting large task binary with size 1590.3 KiB\n",
      "24/03/30 17:45:55 WARN DAGScheduler: Broadcasting large task binary with size 1786.6 KiB\n",
      "24/03/30 17:45:56 WARN DAGScheduler: Broadcasting large task binary with size 1931.5 KiB\n",
      "24/03/30 17:45:56 WARN DAGScheduler: Broadcasting large task binary with size 2035.9 KiB\n",
      "24/03/30 17:45:56 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "24/03/30 17:46:02 WARN DAGScheduler: Broadcasting large task binary with size 1073.9 KiB\n",
      "24/03/30 17:46:02 WARN DAGScheduler: Broadcasting large task binary with size 1202.8 KiB\n",
      "24/03/30 17:46:02 WARN DAGScheduler: Broadcasting large task binary with size 1306.9 KiB\n",
      "24/03/30 17:46:02 WARN DAGScheduler: Broadcasting large task binary with size 1385.0 KiB\n",
      "24/03/30 17:46:02 WARN DAGScheduler: Broadcasting large task binary with size 1434.0 KiB\n",
      "24/03/30 17:46:04 WARN DAGScheduler: Broadcasting large task binary with size 1078.4 KiB\n",
      "24/03/30 17:46:04 WARN DAGScheduler: Broadcasting large task binary with size 1350.7 KiB\n",
      "24/03/30 17:46:06 WARN DAGScheduler: Broadcasting large task binary with size 1078.4 KiB\n",
      "24/03/30 17:46:06 WARN DAGScheduler: Broadcasting large task binary with size 1350.7 KiB\n",
      "24/03/30 17:46:06 WARN DAGScheduler: Broadcasting large task binary with size 1590.9 KiB\n",
      "24/03/30 17:46:06 WARN DAGScheduler: Broadcasting large task binary with size 1784.9 KiB\n",
      "24/03/30 17:46:06 WARN DAGScheduler: Broadcasting large task binary with size 1932.1 KiB\n",
      "24/03/30 17:46:06 WARN DAGScheduler: Broadcasting large task binary with size 2031.2 KiB\n",
      "24/03/30 17:46:06 WARN DAGScheduler: Broadcasting large task binary with size 2033.1 KiB\n",
      "24/03/30 17:46:12 WARN DAGScheduler: Broadcasting large task binary with size 1079.6 KiB\n",
      "24/03/30 17:46:12 WARN DAGScheduler: Broadcasting large task binary with size 1209.8 KiB\n",
      "24/03/30 17:46:12 WARN DAGScheduler: Broadcasting large task binary with size 1309.3 KiB\n",
      "24/03/30 17:46:12 WARN DAGScheduler: Broadcasting large task binary with size 1381.1 KiB\n",
      "24/03/30 17:46:12 WARN DAGScheduler: Broadcasting large task binary with size 1426.6 KiB\n",
      "24/03/30 17:46:14 WARN DAGScheduler: Broadcasting large task binary with size 1083.5 KiB\n",
      "24/03/30 17:46:14 WARN DAGScheduler: Broadcasting large task binary with size 1357.3 KiB\n",
      "24/03/30 17:46:15 WARN DAGScheduler: Broadcasting large task binary with size 1083.5 KiB\n",
      "24/03/30 17:46:15 WARN DAGScheduler: Broadcasting large task binary with size 1357.3 KiB\n",
      "24/03/30 17:46:15 WARN DAGScheduler: Broadcasting large task binary with size 1597.8 KiB\n",
      "24/03/30 17:46:16 WARN DAGScheduler: Broadcasting large task binary with size 1789.0 KiB\n",
      "24/03/30 17:46:16 WARN DAGScheduler: Broadcasting large task binary with size 1927.4 KiB\n",
      "24/03/30 17:46:16 WARN DAGScheduler: Broadcasting large task binary with size 2019.8 KiB\n",
      "24/03/30 17:46:16 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "24/03/30 17:46:22 WARN DAGScheduler: Broadcasting large task binary with size 1096.1 KiB\n",
      "24/03/30 17:46:22 WARN DAGScheduler: Broadcasting large task binary with size 1229.9 KiB\n",
      "24/03/30 17:46:22 WARN DAGScheduler: Broadcasting large task binary with size 1330.1 KiB\n",
      "24/03/30 17:46:22 WARN DAGScheduler: Broadcasting large task binary with size 1402.1 KiB\n",
      "24/03/30 17:46:22 WARN DAGScheduler: Broadcasting large task binary with size 1450.6 KiB\n",
      "24/03/30 17:46:23 WARN DAGScheduler: Broadcasting large task binary with size 1084.3 KiB\n",
      "24/03/30 17:46:24 WARN DAGScheduler: Broadcasting large task binary with size 1355.0 KiB\n",
      "24/03/30 17:46:25 WARN DAGScheduler: Broadcasting large task binary with size 1084.3 KiB\n",
      "24/03/30 17:46:25 WARN DAGScheduler: Broadcasting large task binary with size 1355.0 KiB\n",
      "24/03/30 17:46:25 WARN DAGScheduler: Broadcasting large task binary with size 1591.7 KiB\n",
      "24/03/30 17:46:25 WARN DAGScheduler: Broadcasting large task binary with size 1780.0 KiB\n",
      "24/03/30 17:46:25 WARN DAGScheduler: Broadcasting large task binary with size 1922.4 KiB\n",
      "24/03/30 17:46:25 WARN DAGScheduler: Broadcasting large task binary with size 2023.3 KiB\n",
      "24/03/30 17:46:26 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "24/03/30 17:46:31 WARN DAGScheduler: Broadcasting large task binary with size 1065.7 KiB\n",
      "24/03/30 17:46:32 WARN DAGScheduler: Broadcasting large task binary with size 1205.6 KiB\n",
      "24/03/30 17:46:32 WARN DAGScheduler: Broadcasting large task binary with size 1313.9 KiB\n",
      "24/03/30 17:46:32 WARN DAGScheduler: Broadcasting large task binary with size 1391.3 KiB\n",
      "24/03/30 17:46:32 WARN DAGScheduler: Broadcasting large task binary with size 1377.0 KiB\n",
      "24/03/30 17:46:34 WARN DAGScheduler: Broadcasting large task binary with size 1058.1 KiB\n",
      "24/03/30 17:46:34 WARN DAGScheduler: Broadcasting large task binary with size 1325.4 KiB\n",
      "24/03/30 17:46:35 WARN DAGScheduler: Broadcasting large task binary with size 1058.1 KiB\n",
      "24/03/30 17:46:35 WARN DAGScheduler: Broadcasting large task binary with size 1325.4 KiB\n",
      "24/03/30 17:46:35 WARN DAGScheduler: Broadcasting large task binary with size 1565.3 KiB\n",
      "24/03/30 17:46:36 WARN DAGScheduler: Broadcasting large task binary with size 1762.7 KiB\n",
      "24/03/30 17:46:36 WARN DAGScheduler: Broadcasting large task binary with size 1916.1 KiB\n",
      "24/03/30 17:46:36 WARN DAGScheduler: Broadcasting large task binary with size 2021.2 KiB\n",
      "24/03/30 17:46:36 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "24/03/30 17:46:41 WARN DAGScheduler: Broadcasting large task binary with size 1086.2 KiB\n",
      "24/03/30 17:46:41 WARN DAGScheduler: Broadcasting large task binary with size 1217.9 KiB\n",
      "24/03/30 17:46:41 WARN DAGScheduler: Broadcasting large task binary with size 1316.5 KiB\n",
      "24/03/30 17:46:41 WARN DAGScheduler: Broadcasting large task binary with size 1390.1 KiB\n",
      "24/03/30 17:46:41 WARN DAGScheduler: Broadcasting large task binary with size 1370.5 KiB\n",
      "24/03/30 17:46:43 WARN DAGScheduler: Broadcasting large task binary with size 1075.7 KiB\n",
      "24/03/30 17:46:43 WARN DAGScheduler: Broadcasting large task binary with size 1348.8 KiB\n",
      "24/03/30 17:46:44 WARN DAGScheduler: Broadcasting large task binary with size 1075.7 KiB\n",
      "24/03/30 17:46:45 WARN DAGScheduler: Broadcasting large task binary with size 1348.8 KiB\n",
      "24/03/30 17:46:45 WARN DAGScheduler: Broadcasting large task binary with size 1584.2 KiB\n",
      "24/03/30 17:46:45 WARN DAGScheduler: Broadcasting large task binary with size 1779.1 KiB\n",
      "24/03/30 17:46:45 WARN DAGScheduler: Broadcasting large task binary with size 1935.2 KiB\n",
      "24/03/30 17:46:45 WARN DAGScheduler: Broadcasting large task binary with size 2047.0 KiB\n",
      "24/03/30 17:46:45 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "24/03/30 17:46:51 WARN DAGScheduler: Broadcasting large task binary with size 1061.0 KiB\n",
      "24/03/30 17:46:51 WARN DAGScheduler: Broadcasting large task binary with size 1192.0 KiB\n",
      "24/03/30 17:46:51 WARN DAGScheduler: Broadcasting large task binary with size 1291.3 KiB\n",
      "24/03/30 17:46:51 WARN DAGScheduler: Broadcasting large task binary with size 1362.3 KiB\n",
      "24/03/30 17:46:51 WARN DAGScheduler: Broadcasting large task binary with size 1411.8 KiB\n",
      "24/03/30 17:46:53 WARN DAGScheduler: Broadcasting large task binary with size 1064.3 KiB\n",
      "24/03/30 17:46:53 WARN DAGScheduler: Broadcasting large task binary with size 1328.7 KiB\n",
      "24/03/30 17:46:54 WARN DAGScheduler: Broadcasting large task binary with size 1064.3 KiB\n",
      "24/03/30 17:46:54 WARN DAGScheduler: Broadcasting large task binary with size 1328.7 KiB\n",
      "24/03/30 17:46:54 WARN DAGScheduler: Broadcasting large task binary with size 1553.4 KiB\n",
      "24/03/30 17:46:54 WARN DAGScheduler: Broadcasting large task binary with size 1737.5 KiB\n",
      "24/03/30 17:46:55 WARN DAGScheduler: Broadcasting large task binary with size 1885.8 KiB\n",
      "24/03/30 17:46:55 WARN DAGScheduler: Broadcasting large task binary with size 2002.4 KiB\n",
      "24/03/30 17:46:55 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "24/03/30 17:47:01 WARN DAGScheduler: Broadcasting large task binary with size 1094.6 KiB\n",
      "24/03/30 17:47:01 WARN DAGScheduler: Broadcasting large task binary with size 1230.8 KiB\n",
      "24/03/30 17:47:01 WARN DAGScheduler: Broadcasting large task binary with size 1333.5 KiB\n",
      "24/03/30 17:47:01 WARN DAGScheduler: Broadcasting large task binary with size 1405.6 KiB\n",
      "24/03/30 17:47:01 WARN DAGScheduler: Broadcasting large task binary with size 1454.0 KiB\n",
      "24/03/30 17:47:03 WARN DAGScheduler: Broadcasting large task binary with size 1094.0 KiB\n",
      "24/03/30 17:47:03 WARN DAGScheduler: Broadcasting large task binary with size 1365.2 KiB\n",
      "24/03/30 17:47:04 WARN DAGScheduler: Broadcasting large task binary with size 1094.0 KiB\n",
      "24/03/30 17:47:04 WARN DAGScheduler: Broadcasting large task binary with size 1365.2 KiB\n",
      "24/03/30 17:47:04 WARN DAGScheduler: Broadcasting large task binary with size 1602.2 KiB\n",
      "24/03/30 17:47:04 WARN DAGScheduler: Broadcasting large task binary with size 1791.3 KiB\n",
      "24/03/30 17:47:05 WARN DAGScheduler: Broadcasting large task binary with size 1935.1 KiB\n",
      "24/03/30 17:47:05 WARN DAGScheduler: Broadcasting large task binary with size 2035.8 KiB\n",
      "24/03/30 17:47:05 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "24/03/30 17:47:10 WARN DAGScheduler: Broadcasting large task binary with size 1079.3 KiB\n",
      "24/03/30 17:47:10 WARN DAGScheduler: Broadcasting large task binary with size 1213.3 KiB\n",
      "24/03/30 17:47:10 WARN DAGScheduler: Broadcasting large task binary with size 1317.2 KiB\n",
      "24/03/30 17:47:10 WARN DAGScheduler: Broadcasting large task binary with size 1388.5 KiB\n",
      "24/03/30 17:47:10 WARN DAGScheduler: Broadcasting large task binary with size 1369.3 KiB\n",
      "24/03/30 17:47:12 WARN DAGScheduler: Broadcasting large task binary with size 1083.0 KiB\n",
      "24/03/30 17:47:12 WARN DAGScheduler: Broadcasting large task binary with size 1354.9 KiB\n",
      "24/03/30 17:47:13 WARN DAGScheduler: Broadcasting large task binary with size 1083.0 KiB\n",
      "24/03/30 17:47:13 WARN DAGScheduler: Broadcasting large task binary with size 1354.9 KiB\n",
      "24/03/30 17:47:13 WARN DAGScheduler: Broadcasting large task binary with size 1597.4 KiB\n",
      "24/03/30 17:47:13 WARN DAGScheduler: Broadcasting large task binary with size 1800.6 KiB\n",
      "24/03/30 17:47:14 WARN DAGScheduler: Broadcasting large task binary with size 1960.6 KiB\n",
      "24/03/30 17:47:14 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "24/03/30 17:47:14 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "24/03/30 17:47:20 WARN DAGScheduler: Broadcasting large task binary with size 1109.0 KiB\n",
      "24/03/30 17:47:20 WARN DAGScheduler: Broadcasting large task binary with size 1252.5 KiB\n",
      "24/03/30 17:47:20 WARN DAGScheduler: Broadcasting large task binary with size 1361.0 KiB\n",
      "24/03/30 17:47:20 WARN DAGScheduler: Broadcasting large task binary with size 1430.2 KiB\n",
      "24/03/30 17:47:20 WARN DAGScheduler: Broadcasting large task binary with size 1402.8 KiB\n",
      "24/03/30 17:47:22 WARN DAGScheduler: Broadcasting large task binary with size 1064.4 KiB\n",
      "24/03/30 17:47:22 WARN DAGScheduler: Broadcasting large task binary with size 1329.1 KiB\n",
      "24/03/30 17:47:23 WARN DAGScheduler: Broadcasting large task binary with size 1064.4 KiB\n",
      "24/03/30 17:47:23 WARN DAGScheduler: Broadcasting large task binary with size 1329.1 KiB\n",
      "24/03/30 17:47:23 WARN DAGScheduler: Broadcasting large task binary with size 1566.3 KiB\n",
      "24/03/30 17:47:23 WARN DAGScheduler: Broadcasting large task binary with size 1763.7 KiB\n",
      "24/03/30 17:47:23 WARN DAGScheduler: Broadcasting large task binary with size 1912.3 KiB\n",
      "24/03/30 17:47:24 WARN DAGScheduler: Broadcasting large task binary with size 2012.8 KiB\n",
      "24/03/30 17:47:24 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Define a parameter grid\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(model.numTrees, [10, 20,30]) \\\n",
    "    .addGrid(model.maxDepth, [5, 10,15]) \\\n",
    "    .build()\n",
    "\n",
    "# Configure CrossValidator\n",
    "crossval = CrossValidator(estimator=pipeline2,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=MulticlassClassificationEvaluator(labelCol=\"quality\", predictionCol=\"prediction\", metricName=\"f1\"),\n",
    "                            # evaluator=RegressionEvaluator(labelCol=\"quality\"),\n",
    "                          numFolds=15)\n",
    "\n",
    "# Run cross-validation, and choose the best set of parameters.\n",
    "cvModel = crossval.fit(train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model F1 Score on Test Data: 0.5853148496240602\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on test data\n",
    "predictions = cvModel.transform(test_df)\n",
    "predictions = predictions.withColumn(\"prediction\", round(col(\"prediction\"),0).cast(\"double\"))\n",
    "# Evaluate the best model\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"quality\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "f1_score = evaluator.evaluate(predictions)\n",
    "\n",
    "print(f\"Best Model F1 Score on Test Data: {f1_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------+--------------------+\n",
      "|       prediction|quality|  normalizedFeatures|\n",
      "+-----------------+-------+--------------------+\n",
      "|5.268244298656669|      5|[0.25454545454545...|\n",
      "|4.927972027972028|      5|[0.29090909090909...|\n",
      "|5.009744641323589|      5|[0.29090909090909...|\n",
      "|5.195962732919254|      6|[0.6,0.1095890410...|\n",
      "|5.268244298656669|      5|[0.25454545454545...|\n",
      "+-----------------+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select example rows to display\n",
    "predictions.select(\"prediction\", 'quality', \"normalizedFeatures\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Data source must be a DataFrame or Mapping, not <class 'pyspark.sql.dataframe.DataFrame'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43msns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcatplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcount\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/ml-winequality/.venv/lib/python3.10/site-packages/seaborn/categorical.py:2782\u001b[0m, in \u001b[0;36mcatplot\u001b[0;34m(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, seed, units, weights, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs)\u001b[0m\n\u001b[1;32m   2779\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2780\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot pass values for both `x` and `y`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2782\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[43mPlotter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvariables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2785\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights\u001b[49m\n\u001b[1;32m   2786\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2787\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2788\u001b[0m \u001b[43m    \u001b[49m\u001b[43morient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2789\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Handle special backwards compatibility where pointplot originally\u001b[39;49;00m\n\u001b[1;32m   2790\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# did *not* default to multi-colored unless a palette was specified.\u001b[39;49;00m\n\u001b[1;32m   2791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpoint\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpalette\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlegend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlegend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2793\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2795\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrow\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m   2796\u001b[0m     \u001b[38;5;66;03m# Handle faceting variables that lack name information\u001b[39;00m\n\u001b[1;32m   2797\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m p\u001b[38;5;241m.\u001b[39mvariables \u001b[38;5;129;01mand\u001b[39;00m p\u001b[38;5;241m.\u001b[39mvariables[var] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/workspaces/ml-winequality/.venv/lib/python3.10/site-packages/seaborn/categorical.py:67\u001b[0m, in \u001b[0;36m_CategoricalPlotter.__init__\u001b[0;34m(self, data, variables, order, orient, require_numeric, color, legend)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     58\u001b[0m     data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     legend\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     65\u001b[0m ):\n\u001b[0;32m---> 67\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvariables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# This method takes care of some bookkeeping that is necessary because the\u001b[39;00m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;66;03m# original categorical plots (prior to the 2021 refactor) had some rules that\u001b[39;00m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;66;03m# don't fit exactly into VectorPlotter logic. It may be wise to have a second\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;66;03m# default VectorPlotter rules. If we do decide to make orient part of the\u001b[39;00m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;66;03m# _base variable assignment, we'll want to figure out how to express that.\u001b[39;00m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_format \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwide\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m orient \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m/workspaces/ml-winequality/.venv/lib/python3.10/site-packages/seaborn/_base.py:634\u001b[0m, in \u001b[0;36mVectorPlotter.__init__\u001b[0;34m(self, data, variables)\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;66;03m# var_ordered is relevant only for categorical axis variables, and may\u001b[39;00m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;66;03m# be better handled by an internal axis information object that tracks\u001b[39;00m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;66;03m# such information and is set up by the scale_* methods. The analogous\u001b[39;00m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;66;03m# information for numeric axes would be information about log scales.\u001b[39;00m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_var_ordered \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m}  \u001b[38;5;66;03m# alt., used DefaultDict\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massign_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;66;03m# TODO Lots of tests assume that these are called to initialize the\u001b[39;00m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;66;03m# mappings to default values on class initialization. I'd prefer to\u001b[39;00m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;66;03m# move away from that and only have a mapping when explicitly called.\u001b[39;00m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstyle\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m/workspaces/ml-winequality/.venv/lib/python3.10/site-packages/seaborn/_base.py:679\u001b[0m, in \u001b[0;36mVectorPlotter.assign_variables\u001b[0;34m(self, data, variables)\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;66;03m# When dealing with long-form input, use the newer PlotData\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;66;03m# object (internal but introduced for the objects interface)\u001b[39;00m\n\u001b[1;32m    677\u001b[0m     \u001b[38;5;66;03m# to centralize / standardize data consumption logic.\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_format \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlong\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 679\u001b[0m     plot_data \u001b[38;5;241m=\u001b[39m \u001b[43mPlotData\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    680\u001b[0m     frame \u001b[38;5;241m=\u001b[39m plot_data\u001b[38;5;241m.\u001b[39mframe\n\u001b[1;32m    681\u001b[0m     names \u001b[38;5;241m=\u001b[39m plot_data\u001b[38;5;241m.\u001b[39mnames\n",
      "File \u001b[0;32m/workspaces/ml-winequality/.venv/lib/python3.10/site-packages/seaborn/_core/data.py:57\u001b[0m, in \u001b[0;36mPlotData.__init__\u001b[0;34m(self, data, variables)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     53\u001b[0m     data: DataSource,\n\u001b[1;32m     54\u001b[0m     variables: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, VariableSpec],\n\u001b[1;32m     55\u001b[0m ):\n\u001b[0;32m---> 57\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mhandle_data_source\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m     frame, names, ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_variables(data, variables)\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframe \u001b[38;5;241m=\u001b[39m frame\n",
      "File \u001b[0;32m/workspaces/ml-winequality/.venv/lib/python3.10/site-packages/seaborn/_core/data.py:278\u001b[0m, in \u001b[0;36mhandle_data_source\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Mapping):\n\u001b[1;32m    277\u001b[0m     err \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData source must be a DataFrame or Mapping, not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(data)\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(err)\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[0;31mTypeError\u001b[0m: Data source must be a DataFrame or Mapping, not <class 'pyspark.sql.dataframe.DataFrame'>."
     ]
    }
   ],
   "source": [
    "# EDA \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "sns.catplot(x=\"prediction\",data=predictions,kind='count')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
