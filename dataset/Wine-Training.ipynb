{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in ./.venv/lib/python3.10/site-packages (3.5.1)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.10/site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.10/site-packages (2.2.1)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in ./.venv/lib/python3.10/site-packages (from pyspark) (0.10.9.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# Installing Python packages\n",
    "!pip install pyspark numpy pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import MinMaxScaler, StandardScaler\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import IntegerType, DoubleType\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"WineQualityClassification\").getOrCreate()\n",
    "\n",
    "# Load data\n",
    "data_path = \"/workspaces/ml-winequality/dataset/TrainingDataset.csv\"\n",
    "data = spark.read.csv(data_path, header=True, \n",
    "                      inferSchema=True,\n",
    "                      sep=';'\n",
    "                      ,quote='\"')\n",
    "\n",
    "# Used copilot how to get rid of quotes from colum header\n",
    "new_column_names = [col_name.strip('\"') for col_name in data.columns]\n",
    "data = data.toDF(*new_column_names)\n",
    "\n",
    "# Data preparation\n",
    "feature_cols = data.columns[:-1]  # Assuming last column is 'Quality' which is the label\n",
    "feature_cols\n",
    "\n",
    "# Split the data into training and test sets\n",
    "(trainingData, testData) = data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------------+-----------+--------------+---------+-------------------+--------------------+-------+----+---------+-------+-------+\n",
      "|fixed acidity|volatile acidity|citric acid|residual sugar|chlorides|free sulfur dioxide|total sulfur dioxide|density|  pH|sulphates|alcohol|quality|\n",
      "+-------------+----------------+-----------+--------------+---------+-------------------+--------------------+-------+----+---------+-------+-------+\n",
      "|          8.9|            0.22|       0.48|           1.8|    0.077|               29.0|                60.0| 0.9968|3.39|     0.53|    9.4|      6|\n",
      "|          7.6|            0.39|       0.31|           2.3|    0.082|               23.0|                71.0| 0.9982|3.52|     0.65|    9.7|      5|\n",
      "|          7.9|            0.43|       0.21|           1.6|    0.106|               10.0|                37.0| 0.9966|3.17|     0.91|    9.5|      5|\n",
      "|          8.5|            0.49|       0.11|           2.3|    0.084|                9.0|                67.0| 0.9968|3.17|     0.53|    9.4|      5|\n",
      "|          6.9|             0.4|       0.14|           2.4|    0.085|               21.0|                40.0| 0.9968|3.43|     0.63|    9.7|      6|\n",
      "|          6.3|            0.39|       0.16|           1.4|     0.08|               11.0|                23.0| 0.9955|3.34|     0.56|    9.3|      5|\n",
      "|          7.6|            0.41|       0.24|           1.8|     0.08|                4.0|                11.0| 0.9962|3.28|     0.59|    9.5|      5|\n",
      "|          7.9|            0.43|       0.21|           1.6|    0.106|               10.0|                37.0| 0.9966|3.17|     0.91|    9.5|      5|\n",
      "|          7.1|            0.71|        0.0|           1.9|     0.08|               14.0|                35.0| 0.9972|3.47|     0.55|    9.4|      5|\n",
      "|          7.8|           0.645|        0.0|           2.0|    0.082|                8.0|                16.0| 0.9964|3.38|     0.59|    9.8|      6|\n",
      "+-------------+----------------+-----------+--------------+---------+-------------------+--------------------+-------+----+---------+-------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|quality|count|\n",
      "+-------+-----+\n",
      "|      3|    9|\n",
      "|      4|   45|\n",
      "|      5|  529|\n",
      "|      6|  522|\n",
      "|      7|  161|\n",
      "|      8|   13|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Analyze the distribution of the 'Quality' column\n",
    "quality_distribution = data.groupBy(\"quality\").count().orderBy(\"quality\")\n",
    "quality_distribution.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/30 03:31:50 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-------------------+-------------------+------------------+--------------------+-------------------+--------------------+--------------------+-------------------+------------------+------------------+------------------+\n",
      "|summary|    fixed acidity|   volatile acidity|        citric acid|    residual sugar|           chlorides|free sulfur dioxide|total sulfur dioxide|             density|                 pH|         sulphates|           alcohol|           quality|\n",
      "+-------+-----------------+-------------------+-------------------+------------------+--------------------+-------------------+--------------------+--------------------+-------------------+------------------+------------------+------------------+\n",
      "|  count|             1279|               1279|               1279|              1279|                1279|               1279|                1279|                1279|               1279|              1279|              1279|              1279|\n",
      "|   mean|8.136669272869451| 0.5304026583268179|0.25653635652853685|  2.50512118842846| 0.08653322908522246| 16.082877247849883|   46.00312744331509|  0.9965030023455833| 3.3223377638780343|0.6501954652071926|10.468139171227493|5.6411258795934325|\n",
      "| stddev| 1.62643705835024|0.18019761285860228|0.19234683571822775|1.4281867850973125|0.047000052756637024| 10.548020270224658|   32.45911702682881|0.001814834341261...|0.14877883220527952|0.1551395230836167| 1.059036248732797|0.8098942041137892|\n",
      "|    min|              4.6|               0.12|                0.0|               0.9|               0.034|                1.0|                 6.0|             0.99007|               2.74|              0.33|               8.5|                 3|\n",
      "|    max|             15.6|               1.58|                1.0|              15.4|               0.611|               72.0|               289.0|             1.00369|               4.01|               2.0|              14.0|                 8|\n",
      "+-------+-----------------+-------------------+-------------------+------------------+--------------------+-------------------+--------------------+--------------------+-------------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column fixed acidity has 61 outliers\n",
      "Column volatile acidity has 16 outliers\n",
      "Column citric acid has 1 outliers\n",
      "Column residual sugar has 126 outliers\n",
      "Column chlorides has 94 outliers\n",
      "Column free sulfur dioxide has 25 outliers\n",
      "Column total sulfur dioxide has 52 outliers\n",
      "Column density has 39 outliers\n",
      "Column pH has 24 outliers\n",
      "Column sulphates has 53 outliers\n",
      "Column alcohol has 14 outliers\n",
      "Column quality has 22 outliers\n"
     ]
    }
   ],
   "source": [
    "df=data\n",
    "# List of columns to check for outliers, assuming they are numerical\n",
    "numerical_columns = [column for (column, dtype) in df.dtypes if dtype in ['int', 'double']]\n",
    "\n",
    "outliers = {}\n",
    "\n",
    "for col_name in numerical_columns:\n",
    "    # Calculate Q1 and Q3\n",
    "    quantiles = data.approxQuantile(col_name, [0.25, 0.75], 0.05)\n",
    "    Q1, Q3 = quantiles[0], quantiles[1]\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    # Define bounds for outliers\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # Filter data for outliers\n",
    "    outliers_in_col = df.filter((df[col_name] < lower_bound) | (df[col_name] > upper_bound))\n",
    "    \n",
    "    # You can collect the results, count them, or even show a few\n",
    "    outlier_count = outliers_in_col.count()\n",
    "    print(f\"Column {col_name} has {outlier_count} outliers\")\n",
    "    \n",
    "    # Saving outliers information, for example, as a count\n",
    "    outliers[col_name] = outlier_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Data preparation\n",
    "feature_cols = data.columns[:-1]  # Assuming last column is 'Quality' which is the label\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "labelIndexer = StringIndexer(inputCol=\"quality\", outputCol=\"label\").fit(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.5969750470211647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\")\n",
    "\n",
    "# Pipeline\n",
    "pipeline = Pipeline(stages=[assembler, labelIndexer, rf])\n",
    "\n",
    "# Train model\n",
    "model = pipeline.fit(trainingData)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Evaluate model\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "f1_score = evaluator.evaluate(predictions)\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.write().overwrite().save(\"/workspaces/ml-winequality/model/wine_quality_model\")\n",
    "\n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------------+\n",
      "|minMaxScaledFeatures|standardScaledFeatures|\n",
      "+--------------------+----------------------+\n",
      "|[0.39090909090909...|  [0.46932693965105...|\n",
      "|[0.27272727272727...|  [-0.3299662105669...|\n",
      "|[0.30000000000000...|  [-0.1455139451319...|\n",
      "|[0.35454545454545...|  [0.22339058573783...|\n",
      "|[0.20909090909090...|  [-0.7603548299150...|\n",
      "|[0.15454545454545...|  [-1.1292593607848...|\n",
      "|[0.27272727272727...|  [-0.3299662105669...|\n",
      "|[0.30000000000000...|  [-0.1455139451319...|\n",
      "|[0.22727272727272...|  [-0.6373866529584...|\n",
      "|[0.29090909090909...|  [-0.2069980336102...|\n",
      "|[0.19090909090909...|  [-0.8833230068716...|\n",
      "|[0.20909090909090...|  [-0.7603548299150...|\n",
      "|[0.33636363636363...|  [0.10042240878122...|\n",
      "|[0.20909090909090...|  [-0.7603548299150...|\n",
      "|[0.05454545454545...|  [-1.8055843340462...|\n",
      "|[0.29090909090909...|  [-0.2069980336102...|\n",
      "|[0.29090909090909...|  [-0.2069980336102...|\n",
      "|[0.31818181818181...|  [-0.0225457681753...|\n",
      "|[0.10000000000000...|  [-1.4981638916547...|\n",
      "|[0.24545454545454...|  [-0.5144184760018...|\n",
      "+--------------------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assuming you want to normalize all numeric columns\n",
    "numericCols = [field.name for field in df.schema.fields if isinstance(field.dataType, (IntegerType, DoubleType))]\n",
    "assembler = VectorAssembler(inputCols=numericCols, outputCol=\"features\")\n",
    "\n",
    "# Min-Max Scaling\n",
    "minMaxScaler = MinMaxScaler(inputCol=\"features\", outputCol=\"minMaxScaledFeatures\")\n",
    "\n",
    "# Standard Scaler (Z-score Standardization)\n",
    "standardScaler = StandardScaler(inputCol=\"features\", outputCol=\"standardScaledFeatures\", withMean=True, withStd=True)\n",
    "\n",
    "# Pipeline\n",
    "pipeline = Pipeline(stages=[assembler, minMaxScaler, standardScaler])\n",
    "model = pipeline.fit(df)\n",
    "normalized_df = model.transform(df)\n",
    "\n",
    "# Show results\n",
    "normalized_df.select(\"minMaxScaledFeatures\", \"standardScaledFeatures\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------+--------------------+\n",
      "|       prediction|quality|  normalizedFeatures|\n",
      "+-----------------+-------+--------------------+\n",
      "|6.329782721674169|      7|[0.04545454545454...|\n",
      "| 5.72834470302157|      6|[0.05454545454545...|\n",
      "|6.546227393805317|      7|[0.06363636363636...|\n",
      "|6.546227393805317|      7|[0.06363636363636...|\n",
      "|6.460779601532634|      7|[0.06363636363636...|\n",
      "+-----------------+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.6430449907288762\n"
     ]
    }
   ],
   "source": [
    "# Define the columns to be used as features and the target column\n",
    "featureCols = [field.name for field in df.schema.fields if isinstance(field.dataType, (IntegerType, DoubleType)) and field.name != \"quality\"]\n",
    "targetCol = \"quality\"\n",
    "\n",
    "# Assemble features\n",
    "assembler = VectorAssembler(inputCols=featureCols, outputCol=\"assembledFeatures\")\n",
    "\n",
    "# Normalize features using Min-Max Scaling\n",
    "scaler = MinMaxScaler(inputCol=\"assembledFeatures\", outputCol=\"normalizedFeatures\")\n",
    "\n",
    "# Initialize the model\n",
    "model = RandomForestRegressor(featuresCol=\"normalizedFeatures\", labelCol=targetCol)\n",
    "\n",
    "# Create a Pipeline\n",
    "pipeline = Pipeline(stages=[assembler, scaler, model])\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "(train_data, test_data) = df.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Train the model\n",
    "fitted_pipeline = pipeline.fit(train_data)\n",
    "\n",
    "# Make predictions\n",
    "predictions = fitted_pipeline.transform(test_data)\n",
    "\n",
    "# Select example rows to display\n",
    "predictions.select(\"prediction\", targetCol, \"normalizedFeatures\").show(5)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluator = RegressionEvaluator(labelCol=targetCol, predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"Root Mean Squared Error (RMSE) on test data = {rmse}\")\n",
    "\n",
    "f1_score = evaluator.evaluate(predictions)\n",
    "print(f\"F1 Score: {f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 0.643045\n",
      "MinMaxScalerModel: uid=MinMaxScaler_30e65dde4ff4, numFeatures=11, min=0.0, max=1.0\n"
     ]
    }
   ],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"quality\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "\n",
    "rfModel = fitted_pipeline.stages[1]\n",
    "print(rfModel)  # summary only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data: 0.6585136482676285\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation \n",
    "# Define the columns to be used as features and the target column\n",
    "featureCols = [field.name for field in df.schema.fields if isinstance(field.dataType, (IntegerType, DoubleType)) and field.name != \"quality\"]\n",
    "targetCol = \"quality\"\n",
    "\n",
    "# Assemble features\n",
    "assembler = VectorAssembler(inputCols=featureCols, outputCol=\"assembledFeatures\")\n",
    "\n",
    "# Normalize features using Min-Max Scaling\n",
    "scaler = MinMaxScaler(inputCol=\"assembledFeatures\", outputCol=\"normalizedFeatures\")\n",
    "\n",
    "# Initialize the model\n",
    "model = RandomForestRegressor(featuresCol=\"normalizedFeatures\", labelCol=targetCol)\n",
    "\n",
    "# Create a Pipeline\n",
    "pipeline = Pipeline(stages=[assembler, scaler, model])\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "(train_data, test_data) = df.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Define a parameter grid\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [10, 20, 30,40]) \\\n",
    "    .addGrid(rf.maxDepth, [5, 10, 15,20]) \\\n",
    "    .build()\n",
    "\n",
    "# Set up CrossValidator\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=RegressionEvaluator(labelCol=\"quality\"),\n",
    "                          numFolds=15)\n",
    "\n",
    "# Fit the models and find the best one\n",
    "cvModel = crossval.fit(train_data)\n",
    "\n",
    "# Use the best model to make predictions on the test data\n",
    "predictions = cvModel.transform(test_data)\n",
    "\n",
    "# Evaluate the best model\n",
    "evaluator = RegressionEvaluator(labelCol=\"quality\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"Root Mean Squared Error (RMSE) on test data: {rmse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
